
<!--
    <h2 class="text-3xl mb-4 font-bold" >[demo2] Live Results from Gemini + Function Calling (live OpenAPI call + proper prompting)</h2>
    <p>See this in Demo 4.</p>
    <pre>
        1. Use Gemini f(x) calling with LangchainRb +
        2. Use LangchainRb Tool 'NewsRetriever'
        3. return news to UI.
        4. Summarize. like

        Short story (max 256 token):
        GeminiLLM.summarize(text: 'Please write a night-time story about the evil Amarone daemon who lived in Arena di Verona').raw_response.predictions[0]['content']

        Long story (2048 tokens):
        GeminiLLM.complete(prompt: 'Please write a night-time story about the evil Amarone daemon who lived in Arena di Verona', max_output_tokens: 2047).raw_response.predictions[0]['content']

    </pre>



    -->
