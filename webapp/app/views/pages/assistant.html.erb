<%
@sample_queries_for_gemini_functions = [
    "What's new in US politics?",
    "Latest 9 news on global warming", # not tested
    "Latest 8 news from Google I/O",
    "Latest 5 news on European elections", # not tested
    "latest 3 stories from France",
    "Latest 4 news from Oregon (US)",
    "Latest 5 stories from Italy?",
    "Latest 6 stories from Emila Romagna, in Italy?",
    "Latest 7 news from Vinitaly",
    "Any news from Google Cloud?",
    "Any news about Ruby or RoR?",
    "What are some fun stories from headlines?",
    #"What are some fun facts?", as it is it doesnt work.
  ]

  vertexManhouse = Langchain::LLM::GoogleVertexAI.new(
    project_id: ENV["GOOGLE_VERTEX_AI_PROJECT_ID"],
    region: "us-central1",
    default_options: {        chat_completion_model_name: "gemini-1.5-pro-latest",        }
  )

%>
<div class="assistant-demo" >
    <h1 class="text-4xl font-bold tracking-tight mb-4">ğŸ’ğŸ» Assistant demo</h1>

    <%= demo_button_link('04', 'green') %>

    <% if @query.nil? %>
        <%= render 'pages/assistant_index' %>
    <% else %>

    <%= render( 'pages/assistant_demo_show', llm: VertexLLM, llm_description: "VertexAI LLM - should have good QPS") # rescue "LLM1 error VertexLLM: #{$!}"
    %>
    <%= render( 'pages/assistant_demo_show', llm: GeminiLLM, llm_description: "Gemini LLM (consumer) - should have low QPS") rescue "LLM2 error GeminiLLM: #{$!}" %>
    <%= render( 'pages/assistant_demo_show', llm: vertexManhouse, llm_description: "Vertex Manhouse - in case it behaves differnetly from first vertex Riccardo after lunch just remove the firsty and change with this backfilling in config/initliazers and fix vertexLM there") rescue "LLM3 error vertexManhouse: #{$!}" %>
    <% end %>
</div>
